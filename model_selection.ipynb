{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler\n",
    "import category_encoders as ce\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the train data\n",
    "data = pd.read_csv('Data/cleaned.csv')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outlet_Location_Type = data.Outlet_Location_Type.astype('str')\n",
    "data.select_dtypes(['int', 'float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the OneHotEncoder\n",
    "Encoder = ce.OneHotEncoder(cols=['Item_Fat_Content',\n",
    "                                 'Item_Type',\n",
    "                                'Outlet_Identifier',\n",
    "                                'Outlet_Size',\n",
    "                                'Outlet_Location_Type',\n",
    "                                'Outlet_Type'],use_cat_names=True)\n",
    "# encode the categorical variables\n",
    "data = Encoder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Item_Weight','Item_Visibility','Item_MRP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# fit the Item_MRP and Weight\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a fun to do col selections and split \n",
    "def split_traintest(df, dropvals, yvals = 'Item_Outlet_Sales'):\n",
    "\n",
    "    # separate the predictors and target variable \n",
    "    X = df.drop(columns=dropvals)\n",
    "    Y = data[yvals]\n",
    "\n",
    "    # randomly split the data\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, Y,test_size=0.2,random_state=42)\n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "train_x, test_x, train_y, test_y = split_traintest(data, ['Item_Identifier','Item_Outlet_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape of train and test splits\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baselines\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "\n",
    "models = []\n",
    "models.append(('LM', linear_model.LinearRegression()))\n",
    "models.append(('L1', linear_model.Lasso()))\n",
    "models.append(('L2', linear_model.Ridge()))\n",
    "models.append(('BayesRidge',linear_model.BayesianRidge()))\n",
    "models.append(('Tweedie',linear_model.TweedieRegressor(link='log',  max_iter=5000)))\n",
    "models.append(('RF', RandomForestRegressor(max_depth=10, random_state=0)))\n",
    "# build a pipeline\n",
    "results = []\n",
    "names = []\n",
    "# inspired https://www.kaggle.com/richarde/easy-pipeline-and-model-selection#2.0-Process-the-Data\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds)\n",
    "    cv_results = cross_val_score(model, train_x, train_y,  scoring = 'r2',cv=kfold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s %f %f \" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune glm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the RandomForestRegressor\n",
    "iterations = [5000]\n",
    "links = ['auto', 'identity', 'log']\n",
    "coefs = []\n",
    "results = []\n",
    "names = []\n",
    "for i in links:\n",
    "    model_glm = linear_model.TweedieRegressor( link=i,   max_iter=5000)\n",
    "    # fit the model with the training data\n",
    "    model_glm.fit(train_x, train_y)\n",
    "    # predict the target on train and test data\n",
    "    predict_train = model_glm.predict(train_x)\n",
    "    predict_test = model_glm.predict(test_x)  \n",
    "    # get the coef\n",
    "    coef = pd.Series(model_glm.coef_, model_glm.feature_names_in_, name = 'value').sort_values()\n",
    "    coefs.append(coef)\n",
    "    \n",
    "\n",
    "    print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "    print('r2_score on test data: ',  r2_score(test_y, predict_test))    \n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.scatter(train_y,predict_train)\n",
    "    plt.title( 'Link function ' + str(i) + '(Train data)')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.scatter(test_y,predict_test)\n",
    "    plt.title( 'Link function ' + str(i) + '(Test data)')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    coef[coef>0.1].plot(kind='bar', title='Model Coefficients')\n",
    "    \n",
    "    plt.show()\n",
    "# create an object of the RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'bootstrap': [True],\n",
    "              'max_depth': [5, 10, None], \n",
    "              'max_features': ['auto', 'log2'], \n",
    "              'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]\n",
    "              }\n",
    "              \n",
    "g_search = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, \n",
    "                        cv = 5, n_jobs = 1, verbose = 0,\n",
    "                        return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(coefs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTLET TYPE seems big factor in glm model\n",
    "find a way to convert type 1 to type 3? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'bootstrap': [True],\n",
    "              'max_depth': [5, 10, None], \n",
    "              'max_features': ['auto', 'log2'], \n",
    "              'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]\n",
    "              }\n",
    "              \n",
    "g_search = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, \n",
    "                        cv = 5, n_jobs = 1, verbose = 0,\n",
    "                        return_train_score=True)\n",
    "g_search.fit(train_x, train_y);\n",
    "\n",
    "print(g_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid = pd.concat([pd.DataFrame(g_search.cv_results_[\"params\"]),\n",
    "                     pd.DataFrame(g_search.cv_results_[\"mean_test_score\"], \n",
    "                                  columns=[\"mean_test_score\"]),\n",
    "                     pd.DataFrame(g_search.cv_results_[\"rank_test_score\"], \n",
    "                                  columns=[\"rank_test_score\"])],axis=1)\n",
    "df_grid.to_csv(\"Data/rf_gridsearch.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_rf = RandomForestRegressor( bootstrap=True, max_depth=5, max_features='auto', n_estimators=13, random_state=42) \n",
    "# fit the model with the training data\n",
    "model_rf.fit(train_x, train_y)\n",
    "# predict the target on train and test data\n",
    "predict_train = model_rf.predict(train_x)\n",
    "predict_test = model_rf.predict(test_x)  \n",
    "# get the coef\n",
    "# coef = pd.Series(model_rf.coef_, model_rf.feature_names_in_, name = 'value').sort_values()\n",
    "# coefs.append(coef)\n",
    "\n",
    "print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "print('r2_score on test data: ',  r2_score(test_y, predict_test))    \n",
    "# plt.figure(figsize=(18,6))\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.scatter(train_y,predict_train)\n",
    "# plt.title( 'Link function ' + str(i) + '(Train data)')\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.scatter(test_y,predict_test)\n",
    "# plt.title( 'Link function ' + str(i) + '(Test data)')\n",
    "# plt.subplot(1, 3, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_impt = pd.Series(model_rf.feature_importances_, model_rf.feature_names_in_, name = 'value').sort_values()\n",
    "feature_impt[feature_impt>0.01].plot(kind = 'bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(feature_impt[feature_impt>0]).to_csv('Data/rf_featureimpt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "train_x, test_x, train_y, test_y = split_traintest(data, ['Item_Identifier','Item_Outlet_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "ridge = Ridge()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "train_x = pca.fit_transform(train_x)\n",
    "ridge.fit(train_x, train_y)\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('reduce_dim', PCA()),\n",
    "        ('regressor', linear_model.TweedieRegressor(max_iter=3000))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.fit(train_x, train_y)\n",
    "print('Testing score: ', pipe.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and test errors\n",
    "from sklearn import linear_model\n",
    "alphas = np.logspace(-5, 1, 10)\n",
    "enet = linear_model.ElasticNet(l1_ratio=0.7, max_iter=10000)\n",
    "train_errors = list()\n",
    "test_errors = list()\n",
    "for alpha in alphas:\n",
    "    enet.set_params(alpha=alpha)\n",
    "    enet.fit(train_x, train_y)\n",
    "    train_errors.append(enet.score(train_x, train_y))\n",
    "    test_errors.append(enet.score(test_x, test_y))\n",
    "\n",
    "i_alpha_optim = np.argmax(test_errors)\n",
    "alpha_optim = alphas[i_alpha_optim]\n",
    "print(\"Optimal regularization parameter : %s\" % alpha_optim)\n",
    "\n",
    "# Estimate the coef_ on full data with optimal regularization parameter\n",
    "enet.set_params(alpha=alpha_optim)\n",
    "coef_ = enet.fit(X, Y).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.semilogx(alphas, train_errors, label=\"Train\")\n",
    "plt.semilogx(alphas, test_errors, label=\"Test\")\n",
    "plt.vlines(\n",
    "    alpha_optim,\n",
    "    plt.ylim()[0],\n",
    "    np.max(test_errors),\n",
    "    color=\"k\",\n",
    "    linewidth=3,\n",
    "    label=\"Optimum on test\",\n",
    ")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.ylim([0, 1.2])\n",
    "plt.xlabel(\"Regularization parameter\")\n",
    "plt.ylabel(\"Performance\")\n",
    "\n",
    "# Show estimated coef_ vs true coef\n",
    "plt.subplot(2, 1, 2)\n",
    "\n",
    "plt.plot(coef_, label=\"Estimated coef\")\n",
    "plt.legend()\n",
    "plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "513dc2e41d739bb2c947903f3c0bbf636d03aa53ab50e61c694a27481c81805e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
