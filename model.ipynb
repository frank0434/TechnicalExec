{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals:\n",
    "-\tBuild a model to predict the number of sales (Item_Outlet_Sales) using the available features.\n",
    "-\tGain insights about the number of sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the train data\n",
    "data = pd.read_csv('Data\\BigMart.csv')\n",
    "# check for the null values\n",
    "data.isna().sum()\n",
    "# Drop row number \n",
    "data.drop(\"Unnamed: 0\", axis = 1, inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Item_Weight.hist()\n",
    "data.Outlet_Size.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n",
    "df_ = data.select_dtypes(exclude=['int', 'float'])\n",
    "for col in df_.columns:\n",
    "    print(df_[col].unique()) # to print categories name only\n",
    "    # print(df_[col].value_counts()) # to print count of every category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix some irregular values \n",
    "data.loc[data['Item_Fat_Content'].isin(['LF','low fat']), 'Item_Fat_Content'] = 'Low Fat'\n",
    "data.loc[data['Item_Fat_Content'].isin(['reg']), 'Item_Fat_Content'] = 'Regular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute NAs by mean\n",
    "data.Item_Weight.fillna(data.Item_Weight.mean(),inplace=True)\n",
    "# during EDA in R, discovered NAs present in Grocery and Supermarket type 1. \n",
    "# assume Grocery store are small and use mode for Type1 supermarket \n",
    "\n",
    "data.loc[:, ['Outlet_Type', 'Outlet_Size']].drop_duplicates()\n",
    "data.loc[data['Outlet_Type'].eq('Grocery Store') & data['Outlet_Size'].isna(), 'Outlet_Size'] = 'Small'\n",
    "data.Outlet_Size.mode()\n",
    "data.loc[data['Outlet_Type'].eq('Supermarket Type1') & data['Outlet_Size'].isna(), 'Outlet_Size'] = 'Medium'\n",
    "data.loc[:, ['Outlet_Type', 'Outlet_Size']].drop_duplicates()\n",
    "data.loc[:, ['Item_Type']].drop_duplicates()\n",
    "data.Outlet_Location_Type = data.Outlet_Location_Type.astype('str')\n",
    "# save it \n",
    "data.to_csv(\"Data/cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preProcessing \n",
    "\n",
    "### Code categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the OneHotEncoder\n",
    "Encoder = ce.OneHotEncoder(cols=['Item_Fat_Content',\n",
    "                                 'Item_Type',\n",
    "                                 'Outlet_Identifier',\n",
    "                                 'Outlet_Size',\n",
    "                                 'Outlet_Location_Type',\n",
    "                                 'Outlet_Type'],\n",
    "                                 use_cat_names=True)\n",
    "# encode the categorical variables\n",
    "data = Encoder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general information about the data\n",
    "data.isna().sum()\n",
    "data.describe()\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarise numeric variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the StandardScaler \n",
    "scaler = StandardScaler()\n",
    "# fit the Item_MRP and Weigh, and visibility \n",
    "num_cols = ['Item_Weight','Item_Visibility','Item_MRP']\n",
    "# fit the Item_MRP and Weight and visibility\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data to train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the predictors and target variable \n",
    "train_X = data.drop(columns=['Item_Identifier','Item_Outlet_Sales'])\n",
    "train_Y = data['Item_Outlet_Sales']\n",
    "\n",
    "# randomly split the data\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_X, train_Y,test_size=0.2,random_state=0)\n",
    "\n",
    "# shape of train and test splits\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the LinearRegression Model\n",
    "model_LR = linear_model.LinearRegression(fit_intercept=False)\n",
    "\n",
    "# fit the model with the training data\n",
    "model_LR.fit(train_x, train_y)\n",
    "\n",
    "# predict the target on train and test data \n",
    "predict_train = model_LR.predict(train_x)\n",
    "predict_test  = model_LR.predict(test_x)\n",
    "\n",
    "print('RMSE on train data: ', mean_squared_error(train_y, predict_train))\n",
    "print('RMSE on test data: ',  mean_squared_error(test_y, predict_test))\n",
    "print('MAE on train data: ', mean_absolute_error(train_y, predict_train))\n",
    "print('MAE on test data: ',  mean_absolute_error(test_y, predict_test))\n",
    "print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "print('r2_score on test data: ',  r2_score(test_y, predict_test))\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(train_y,predict_train)\n",
    "# plt.title( 'Link function ' + str(i) + '(Train data)')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(test_y,predict_test)\n",
    "# plt.title( 'Link function ' + str(i) + '(Test data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract feature coefs\n",
    "d = {'featurename':model_LR.feature_names_in_, \n",
    "     'featurecoef':model_LR.coef_}\n",
    "# coef = pd.Series(model_LR.coef_, model_LR.feature_names_in_, name = 'value').sort_values()\n",
    "\n",
    "pd.DataFrame(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output evaluation results \n",
    "pd.DataFrame({'obs':test_y, 'pred':predict_test}).to_csv('Data/lmtestrs.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the RandomForestRegressor\n",
    "model_RFR = RandomForestRegressor(max_depth=10)\n",
    "\n",
    "# fit the model with the training data\n",
    "model_RFR.fit(train_x, train_y)\n",
    "\n",
    "# predict the target on train and test data\n",
    "predict_train = model_RFR.predict(train_x)\n",
    "predict_test = model_RFR.predict(test_x)\n",
    "\n",
    "print('RMSE on train data: ', mean_squared_error(train_y, predict_train))\n",
    "print('RMSE on test data: ',  mean_squared_error(test_y, predict_test))\n",
    "print('MAE on train data: ', mean_absolute_error(train_y, predict_train))\n",
    "print('MAE on test data: ',  mean_absolute_error(test_y, predict_test))\n",
    "print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "print('r2_score on test data: ',  r2_score(test_y, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF is better than LR so far. But overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a lasso regression to drop some features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "regressor = linear_model.Lasso(alpha=100,  \n",
    "                               positive=True,\n",
    "                               fit_intercept=False, \n",
    "                               max_iter=1000,\n",
    "                               tol=0.0001)\n",
    "regressor.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "eli5.show_weights(regressor, top=-1, feature_names = train_x.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_L1=pd.DataFrame({'name': regressor.feature_names_in_,\n",
    "              'coefs': regressor.coef_})\n",
    "df_L1[df_L1['coefs' ]> 0 ].sort_values(by='coefs', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five features lead the way? \n",
    "Not sure if it's going to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respilt the data\n",
    "train_X = data.loc[:,df_L1[df_L1['coefs' ]> 0 ].name.tolist()]\n",
    "train_Y = data['Item_Outlet_Sales']\n",
    "\n",
    "# split the data\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_X, train_Y,test_size=0.2,random_state=0)\n",
    "\n",
    "# shape of train and test splits\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the LinearRegression Model\n",
    "model_LR = linear_model.LinearRegression()\n",
    "\n",
    "# fit the model with the training data\n",
    "model_LR.fit(train_x, train_y)\n",
    "\n",
    "# predict the target on train and test data \n",
    "predict_train = model_LR.predict(train_x)\n",
    "predict_test  = model_LR.predict(test_x)\n",
    "\n",
    "# Root Mean Squared Error on train and test date\n",
    "print('RMSE on train data: ', mean_squared_error(train_y, predict_train))\n",
    "print('RMSE on test data: ',  mean_squared_error(test_y, predict_test))\n",
    "print('MAE on train data: ', mean_absolute_error(train_y, predict_train))\n",
    "print('MAE on test data: ',  mean_absolute_error(test_y, predict_test))\n",
    "print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "print('r2_score on test data: ',  r2_score(test_y, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the RandomForestRegressor\n",
    "model_RFR = RandomForestRegressor(max_depth=10)\n",
    "\n",
    "# fit the model with the training data\n",
    "model_RFR.fit(train_x, train_y)\n",
    "\n",
    "# predict the target on train and test data\n",
    "predict_train = model_RFR.predict(train_x)\n",
    "predict_test = model_RFR.predict(test_x)\n",
    "\n",
    "# Root Mean Squared Error on train and test data\n",
    "print('RMSE on train data: ', mean_squared_error(train_y, predict_train)**(0.5))\n",
    "print('RMSE on test data: ',  mean_squared_error(test_y, predict_test)**(0.5))\n",
    "print('MAE on train data: ', mean_absolute_error(train_y, predict_train))\n",
    "print('MAE on test data: ',  mean_absolute_error(test_y, predict_test))\n",
    "print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "print('r2_score on test data: ',  r2_score(test_y, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not doing great\n",
    "Need a pipleline and see more models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepara data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the train data\n",
    "data = pd.read_csv('Data/cleaned.csv')\n",
    "Encoder = ce.OneHotEncoder(cols=['Item_Fat_Content',\n",
    "                                 'Item_Type',\n",
    "                                'Outlet_Identifier',\n",
    "                                'Outlet_Size',\n",
    "                                'Outlet_Location_Type',\n",
    "                                'Outlet_Type'],use_cat_names=True)\n",
    "# encode the categorical variables\n",
    "data = Encoder.fit_transform(data)\n",
    "num_cols = ['Item_Weight','Item_Visibility','Item_MRP']\n",
    "scaler = StandardScaler()\n",
    "# fit the Item_MRP and Weight\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "\n",
    "# define a fun to do col selections and split \n",
    "def split_traintest(df, dropvals, yvals = 'Item_Outlet_Sales'):\n",
    "\n",
    "    # separate the predictors and target variable \n",
    "    X = df.drop(columns=dropvals)\n",
    "    Y = data[yvals]\n",
    "\n",
    "    # randomly split the data\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, Y,test_size=0.2,random_state=42)\n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "train_x, test_x, train_y, test_y = split_traintest(data, ['Item_Identifier','Item_Outlet_Sales'])\n",
    "# check shape of train and test splits\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try six with 10 fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baselines\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "\n",
    "models = []\n",
    "models.append(('LM', linear_model.LinearRegression()))\n",
    "models.append(('L1', linear_model.Lasso()))\n",
    "models.append(('L2', linear_model.Ridge()))\n",
    "models.append(('BayesRidge',linear_model.BayesianRidge()))\n",
    "models.append(('GLM',linear_model.TweedieRegressor(link='log',  max_iter=3000)))\n",
    "models.append(('RF', RandomForestRegressor(max_depth=10, random_state=0)))\n",
    "# build a pipeline\n",
    "results = []\n",
    "names = []\n",
    "# copied from  https://www.kaggle.com/richarde/easy-pipeline-and-model-selection#2.0-Process-the-Data\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds)\n",
    "    cv_results = cross_val_score(model, train_x, train_y,  scoring = 'r2',cv=kfold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s %f %f \" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "plt.savefig('Reports/baselines.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save output for visualisation in R\n",
    "rs_hold = [item for sublist in results for item in sublist]\n",
    "df = pd.DataFrame({'names' :np.repeat(['LM','L1','L2','BayeL2', 'GLM', 'RF'], 10),\n",
    "                   'r2':rs_hold})\n",
    "## output \n",
    "df.to_csv('Data/baselines.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning \n",
    "\n",
    "### GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the RandomForestRegressor\n",
    "iterations = [5000]\n",
    "links = ['log']\n",
    "coefs = []\n",
    "results = []\n",
    "names = []\n",
    "for i in links:\n",
    "    model_glm = linear_model.TweedieRegressor( link=i,   max_iter=5000)\n",
    "    # fit the model with the training data\n",
    "    model_glm.fit(train_x, train_y)\n",
    "    # predict the target on train and test data\n",
    "    predict_train = model_glm.predict(train_x)\n",
    "    predict_test = model_glm.predict(test_x)  \n",
    "    # get the coef\n",
    "    coef = pd.Series(model_glm.coef_, model_glm.feature_names_in_, name = 'value').sort_values()\n",
    "    coefs.append(coef)    \n",
    "\n",
    "    print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "    print('r2_score on test data: ',  r2_score(test_y, predict_test))    \n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.scatter(train_y,predict_train)\n",
    "    plt.title( 'Link function ' + str(i) + '(Train data)')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.scatter(test_y,predict_test)\n",
    "    plt.title( 'Link function ' + str(i) + '(Test data)')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    coef[coef>0.1].plot(kind='bar', title='Model Coefficients')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "## Save coefs \n",
    "pd.DataFrame(coefs).to_csv('Data/glm.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RandomForestRegressor\n",
    "param_grid = {'bootstrap': [True],\n",
    "              'max_depth': [5, 10, None], \n",
    "              'max_features': ['auto', 'log2'], \n",
    "              'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]\n",
    "              }\n",
    "              \n",
    "g_search = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, \n",
    "                        cv = 5, n_jobs = 1, verbose = 0,\n",
    "                        return_train_score=True)\n",
    "g_search.fit(train_x, train_y)\n",
    "## save output \n",
    "df_grid = pd.concat([pd.DataFrame(g_search.cv_results_[\"params\"]),\n",
    "                     pd.DataFrame(g_search.cv_results_[\"mean_test_score\"], \n",
    "                                  columns=[\"mean_test_score\"]),\n",
    "                     pd.DataFrame(g_search.cv_results_[\"rank_test_score\"], \n",
    "                                  columns=[\"rank_test_score\"])],axis=1)\n",
    "df_grid.to_csv(\"Data/rf_gridsearch.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_rf = RandomForestRegressor( bootstrap=True, max_depth=5, max_features='auto', n_estimators=13, random_state=42) \n",
    "# fit the model with the training data\n",
    "model_rf.fit(train_x, train_y)\n",
    "# predict the target on train and test data\n",
    "predict_train = model_rf.predict(train_x)\n",
    "predict_test = model_rf.predict(test_x)  \n",
    "# get the coef\n",
    "# coef = pd.Series(model_rf.coef_, model_rf.feature_names_in_, name = 'value').sort_values()\n",
    "# coefs.append(coef)\n",
    "\n",
    "print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "print('r2_score on test data: ',  r2_score(test_y, predict_test))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## best performer \n",
    "feature_impt = pd.Series(model_rf.feature_importances_, model_rf.feature_names_in_, name = 'value').sort_values()\n",
    "feature_impt[feature_impt>0.01].plot(kind = 'bar')\n",
    "## save output \n",
    "pd.DataFrame(feature_impt[feature_impt>0]).to_csv('Data/rf_featureimpt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting some useful figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the predictors and target variable \n",
    "train_X = data.drop(columns=['Item_Identifier','Item_Outlet_Sales'])\n",
    "train_Y = data['Item_Outlet_Sales']\n",
    "\n",
    "# randomly split the data\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_X, train_Y,test_size=0.2,random_state=0)\n",
    "\n",
    "# shape of train and test splits\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape\n",
    "\n",
    "\n",
    "# Try plot a learning curve\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "# Instantiate the regression model and visualizer\n",
    "model = linear_model.LinearRegression()\n",
    "visualizer = LearningCurve(model, scoring='r2')\n",
    "\n",
    "visualizer.fit(train_X, train_Y)        # Fit the data to the visualizer\n",
    "visualizer.show('Reports/lmlearningcurve.png')           # Finalize and render the figure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import ValidationCurve\n",
    "viz = ValidationCurve(\n",
    "    RandomForestRegressor(), param_name=\"max_depth\",\n",
    "    param_range=np.arange(1, 11), cv=10, scoring=\"r2\"\n",
    ")\n",
    "\n",
    "# Fit and show the visualizer\n",
    "viz.fit(train_X, train_Y)\n",
    "viz.show(outpath='Reports/rf_maxdepth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "model = linear_model.TweedieRegressor(link='log',   max_iter=3000)\n",
    "visualizer = LearningCurve(model, scoring='r2')\n",
    "\n",
    "visualizer.fit(train_x, train_y)        # Fit the data to the visualizer\n",
    "visualizer.show(outpath= 'Reports/glmLearningCurve.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and test errors\n",
    "from sklearn import linear_model\n",
    "alphas = np.logspace(-5, 1, 10)\n",
    "enet = linear_model.ElasticNet(l1_ratio=0.7, max_iter=10000)\n",
    "train_errors = list()\n",
    "test_errors = list()\n",
    "for alpha in alphas:\n",
    "    enet.set_params(alpha=alpha)\n",
    "    enet.fit(train_x, train_y)\n",
    "    train_errors.append(enet.score(train_x, train_y))\n",
    "    test_errors.append(enet.score(test_x, test_y))\n",
    "\n",
    "i_alpha_optim = np.argmax(test_errors)\n",
    "alpha_optim = alphas[i_alpha_optim]\n",
    "print(\"Optimal regularization parameter : %s\" % alpha_optim)\n",
    "\n",
    "# Estimate the coef_ on full data with optimal regularization parameter\n",
    "enet.set_params(alpha=alpha_optim)\n",
    "coef_ = enet.fit(train_x, train_y).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.semilogx(alphas, train_errors, label=\"Train\")\n",
    "plt.semilogx(alphas, test_errors, label=\"Test\")\n",
    "plt.vlines(\n",
    "    alpha_optim,\n",
    "    plt.ylim()[0],\n",
    "    np.max(test_errors),\n",
    "    color=\"k\",\n",
    "    linewidth=3,\n",
    "    label=\"Optimum on test\",\n",
    ")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.ylim([0, 1.2])\n",
    "plt.xlabel(\"Regularization parameter\")\n",
    "plt.ylabel(\"Performance\")\n",
    "\n",
    "# Show estimated coef_ vs true coef\n",
    "plt.subplot(2, 1, 2)\n",
    "\n",
    "plt.plot(coef_, label=\"Estimated coef\")\n",
    "plt.legend()\n",
    "plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some feature enigeering change supermarket type 2 to 1\n",
    "\n",
    "# data.loc[data['Item_Type'].isin(['Household', 'Health and Hygiene']), 'Item_Type'] = 'Noneedible'\n",
    "# data.loc[data['Outlet_Type'].eq('Supermarket Type2'), 'Outlet_Type'] = 'Supermarket Type1'"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "513dc2e41d739bb2c947903f3c0bbf636d03aa53ab50e61c694a27481c81805e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
