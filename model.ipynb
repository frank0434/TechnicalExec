{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals:\n",
    "-\tBuild a model to predict the number of sales (Item_Outlet_Sales) using the available features.\n",
    "-\tGain insights about the number of sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the train data\n",
    "data = pd.read_csv('Data\\BigMart.csv')\n",
    "# check for the null values\n",
    "data.isna().sum()\n",
    "# Drop row number \n",
    "data.drop(\"Unnamed: 0\", axis = 1, inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Item_Weight.hist()\n",
    "data.Outlet_Size.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n",
    "df_ = data.select_dtypes(exclude=['int', 'float'])\n",
    "for col in df_.columns:\n",
    "    print(df_[col].unique()) # to print categories name only\n",
    "    # print(df_[col].value_counts()) # to print count of every category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix some irregular values \n",
    "data.loc[data['Item_Fat_Content'].isin(['LF','low fat']), 'Item_Fat_Content'] = 'Low Fat'\n",
    "data.loc[data['Item_Fat_Content'].isin(['reg']), 'Item_Fat_Content'] = 'Regular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute NAs by mean\n",
    "data.Item_Weight.fillna(data.Item_Weight.mean(),inplace=True)\n",
    "# during EDA in R, discovered NAs present in Grocery and Supermarket type 1. \n",
    "# assume Grocery store are small and use mode for Type1 supermarket \n",
    "\n",
    "data.loc[:, ['Outlet_Type', 'Outlet_Size']].drop_duplicates()\n",
    "data.loc[data['Outlet_Type'].eq('Grocery Store') & data['Outlet_Size'].isna(), 'Outlet_Size'] = 'Small'\n",
    "data.Outlet_Size.mode()\n",
    "data.loc[data['Outlet_Type'].eq('Supermarket Type1') & data['Outlet_Size'].isna(), 'Outlet_Size'] = 'Medium'\n",
    "data.loc[:, ['Outlet_Type', 'Outlet_Size']].drop_duplicates()\n",
    "data.loc[:, ['Item_Type']].drop_duplicates()\n",
    "data.Outlet_Location_Type = data.Outlet_Location_Type.astype('str')\n",
    "# save it \n",
    "data.to_csv(\"Data/cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the OneHotEncoder\n",
    "Encoder = ce.OneHotEncoder(cols=['Item_Fat_Content',\n",
    "                                 'Item_Type',\n",
    "                                'Outlet_Identifier',\n",
    "                                'Outlet_Size',\n",
    "                                'Outlet_Location_Type',\n",
    "                                'Outlet_Type'],use_cat_names=True)\n",
    "# encode the categorical variables\n",
    "data = Encoder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some feature enigeering change supermarket type 2 to 1\n",
    "\n",
    "# data.loc[data['Item_Type'].isin(['Household', 'Health and Hygiene']), 'Item_Type'] = 'Noneedible'\n",
    "# data.loc[data['Outlet_Type'].eq('Supermarket Type2'), 'Outlet_Type'] = 'Supermarket Type1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()\n",
    "data.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# fit the Item_MRP and Weight\n",
    "num_cols = ['Item_Weight','Item_Visibility','Item_MRP']\n",
    "\n",
    "# fit the Item_MRP and Weight\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the predictors and target variable \n",
    "train_X = data.drop(columns=['Item_Identifier','Item_Outlet_Sales'])\n",
    "train_Y = data['Item_Outlet_Sales']\n",
    "\n",
    "# randomly split the data\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_X, train_Y,test_size=0.2,random_state=0)\n",
    "\n",
    "# shape of train and test splits\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try plot a learning curve\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "# Instantiate the regression model and visualizer\n",
    "model = LinearRegression()\n",
    "visualizer = LearningCurve(model, scoring='r2')\n",
    "\n",
    "visualizer.fit(train_X, train_Y)        # Fit the data to the visualizer\n",
    "visualizer.show('Reports/lmlearningcurve.png')           # Finalize and render the figure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import ValidationCurve\n",
    "\n",
    "\n",
    "\n",
    "viz = ValidationCurve(\n",
    "    RandomForestRegressor(), param_name=\"max_depth\",\n",
    "    param_range=np.arange(1, 11), cv=10, scoring=\"r2\"\n",
    ")\n",
    "\n",
    "# Fit and show the visualizer\n",
    "viz.fit(train_X, train_Y)\n",
    "viz.show(outpath='Reports/rf_maxdepth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "from sklearn import linear_model\n",
    "model = linear_model.TweedieRegressor(link='log', max_iter=1000)\n",
    "visualizer = LearningCurve(model, scoring='r2')\n",
    "\n",
    "visualizer.fit(train_X, train_Y)        # Fit the data to the visualizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error2 = pd.DataFrame({'Actual-Values': np.array(y_test).flatten(), 'Predicted-Values': predi.flatten()})\n",
    "error2.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.show(outpath= 'Reports/glmLearningCurve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the LinearRegression Model\n",
    "model_LR = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# fit the model with the training data\n",
    "model_LR.fit(train_x, train_y)\n",
    "\n",
    "# predict the target on train and test data \n",
    "predict_train = model_LR.predict(train_x)\n",
    "predict_test  = model_LR.predict(test_x)\n",
    "\n",
    "print('RMSE on train data: ', mean_squared_error(train_y, predict_train))\n",
    "print('RMSE on test data: ',  mean_squared_error(test_y, predict_test))\n",
    "print('MAE on train data: ', mean_absolute_error(train_y, predict_train))\n",
    "print('MAE on test data: ',  mean_absolute_error(test_y, predict_test))\n",
    "print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "print('r2_score on test data: ',  r2_score(test_y, predict_test))\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(train_y,predict_train)\n",
    "# plt.title( 'Link function ' + str(i) + '(Train data)')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(test_y,predict_test)\n",
    "# plt.title( 'Link function ' + str(i) + '(Test data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'featurename':model_LR.feature_names_in_, \n",
    "     'featurecoef':model_LR.coef_}\n",
    "# coef = pd.Series(model_LR.coef_, model_LR.feature_names_in_, name = 'value').sort_values()\n",
    "\n",
    "pd.DataFrame(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'obs':test_y, 'pred':predict_test}).to_csv('Data/lmtestrs.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the RandomForestRegressor\n",
    "model_RFR = RandomForestRegressor(max_depth=10)\n",
    "\n",
    "# fit the model with the training data\n",
    "model_RFR.fit(train_x, train_y)\n",
    "\n",
    "# predict the target on train and test data\n",
    "predict_train = model_RFR.predict(train_x)\n",
    "predict_test = model_RFR.predict(test_x)\n",
    "\n",
    "print('RMSE on train data: ', mean_squared_error(train_y, predict_train))\n",
    "print('RMSE on test data: ',  mean_squared_error(test_y, predict_test))\n",
    "print('MAE on train data: ', mean_absolute_error(train_y, predict_train))\n",
    "print('MAE on test data: ',  mean_absolute_error(test_y, predict_test))\n",
    "print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "print('r2_score on test data: ',  r2_score(test_y, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF is better than LR so far. But overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a lasso regression to drop some features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "regressor = linear_model.Lasso(alpha=100,  \n",
    "                               positive=True,\n",
    "                               fit_intercept=False, \n",
    "                               max_iter=1000,\n",
    "                               tol=0.0001)\n",
    "regressor.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "eli5.show_weights(regressor, top=-1, feature_names = train_x.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features lead the way? \n",
    "Not sure if it's going to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the independent and target variable \n",
    "train_X = data.loc[:,['Item_MRP', 'Outlet_Identifier_OUT027', 'Outlet_Type_Supermarket Type1', 'Outlet_Size_Medium']]\n",
    "train_Y = data['Item_Outlet_Sales']\n",
    "\n",
    "# split the data\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_X, train_Y,test_size=0.2,random_state=0)\n",
    "\n",
    "# shape of train and test splits\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create an object of the LinearRegression Model\n",
    "model_LR = LinearRegression()\n",
    "\n",
    "# fit the model with the training data\n",
    "model_LR.fit(train_x, train_y)\n",
    "\n",
    "# predict the target on train and test data \n",
    "predict_train = model_LR.predict(train_x)\n",
    "predict_test  = model_LR.predict(test_x)\n",
    "\n",
    "# Root Mean Squared Error on train and test date\n",
    "print('RMSE on train data: ', mean_squared_error(train_y, predict_train))\n",
    "print('RMSE on test data: ',  mean_squared_error(test_y, predict_test))\n",
    "print('MAE on train data: ', mean_absolute_error(train_y, predict_train))\n",
    "print('MAE on test data: ',  mean_absolute_error(test_y, predict_test))\n",
    "print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "print('r2_score on test data: ',  r2_score(test_y, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the RandomForestRegressor\n",
    "model_RFR = RandomForestRegressor(max_depth=10)\n",
    "\n",
    "# fit the model with the training data\n",
    "model_RFR.fit(train_x, train_y)\n",
    "\n",
    "# predict the target on train and test data\n",
    "predict_train = model_RFR.predict(train_x)\n",
    "predict_test = model_RFR.predict(test_x)\n",
    "\n",
    "# Root Mean Squared Error on train and test data\n",
    "print('RMSE on train data: ', mean_squared_error(train_y, predict_train)**(0.5))\n",
    "print('RMSE on test data: ',  mean_squared_error(test_y, predict_test)**(0.5))\n",
    "print('MAE on train data: ', mean_absolute_error(train_y, predict_train))\n",
    "print('MAE on test data: ',  mean_absolute_error(test_y, predict_test))\n",
    "print('r2_score on train data: ', r2_score(train_y, predict_train))\n",
    "print('r2_score on test data: ',  r2_score(test_y, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not doing great\n",
    "Need a pipleline and model selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a cleaned dataset \n",
    "data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "513dc2e41d739bb2c947903f3c0bbf636d03aa53ab50e61c694a27481c81805e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
